{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(\"inshorts data preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Headline_lemma</th>\n",
       "      <th>Short_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Politics</td>\n",
       "      <td>stopped entering studio time arnab</td>\n",
       "      <td>tv news anchor arnab goswami said told could p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>new trailer justice league released</td>\n",
       "      <td>new trailer upcoming superhero film justice le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>touch right shilpa shinde sexual harassment</td>\n",
       "      <td>television actress shilpa shinde opening claim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Politics</td>\n",
       "      <td>antiromeo squad must trouble consenting youth ...</td>\n",
       "      <td>uttar pradesh chief minister yogi adityanath v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Politics</td>\n",
       "      <td>romeo juliet welcome delhi aap minister</td>\n",
       "      <td>apparent jibe ups antiromeo squad delhi touris...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Subject                                     Headline_lemma  \\\n",
       "0       Politics                 stopped entering studio time arnab   \n",
       "1  Entertainment                new trailer justice league released   \n",
       "2  Entertainment        touch right shilpa shinde sexual harassment   \n",
       "3       Politics  antiromeo squad must trouble consenting youth ...   \n",
       "4       Politics            romeo juliet welcome delhi aap minister   \n",
       "\n",
       "                                         Short_lemma  \n",
       "0  tv news anchor arnab goswami said told could p...  \n",
       "1  new trailer upcoming superhero film justice le...  \n",
       "2  television actress shilpa shinde opening claim...  \n",
       "3  uttar pradesh chief minister yogi adityanath v...  \n",
       "4  apparent jibe ups antiromeo squad delhi touris...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25196, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.loc[14000:16000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Headline_lemma</th>\n",
       "      <th>Short_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14000</th>\n",
       "      <td>Politics</td>\n",
       "      <td>uk ban fishing million sq km ocean</td>\n",
       "      <td>uk government thursday said ban commercial fis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14001</th>\n",
       "      <td>Politics</td>\n",
       "      <td>iimc get upgraded university naidu</td>\n",
       "      <td>process upgrade indian institute mass communic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14002</th>\n",
       "      <td>Politics</td>\n",
       "      <td>west bengal give acre land volvo</td>\n",
       "      <td>west bengal chief minister mamata banerjee thu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14003</th>\n",
       "      <td>Politics</td>\n",
       "      <td>vijaya lakshmi st female un general assembly prez</td>\n",
       "      <td>indian diplomat politician vijaya lakshmi pand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14004</th>\n",
       "      <td>Politics</td>\n",
       "      <td>tax board honour lakh honest taxpayer</td>\n",
       "      <td>central board direct tax honour lakh honest co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Subject                                     Headline_lemma  \\\n",
       "14000  Politics                 uk ban fishing million sq km ocean   \n",
       "14001  Politics                 iimc get upgraded university naidu   \n",
       "14002  Politics                   west bengal give acre land volvo   \n",
       "14003  Politics  vijaya lakshmi st female un general assembly prez   \n",
       "14004  Politics              tax board honour lakh honest taxpayer   \n",
       "\n",
       "                                             Short_lemma  \n",
       "14000  uk government thursday said ban commercial fis...  \n",
       "14001  process upgrade indian institute mass communic...  \n",
       "14002  west bengal chief minister mamata banerjee thu...  \n",
       "14003  indian diplomat politician vijaya lakshmi pand...  \n",
       "14004  central board direct tax honour lakh honest co...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc =OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrdinalEncoder()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 =df2[['Subject']]\n",
    "enc.fit(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df2['Subejct_encoded']=enc.transform(df2[['Subject']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Headline_lemma</th>\n",
       "      <th>Short_lemma</th>\n",
       "      <th>Subejct_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14000</th>\n",
       "      <td>Politics</td>\n",
       "      <td>uk ban fishing million sq km ocean</td>\n",
       "      <td>uk government thursday said ban commercial fis...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14001</th>\n",
       "      <td>Politics</td>\n",
       "      <td>iimc get upgraded university naidu</td>\n",
       "      <td>process upgrade indian institute mass communic...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14002</th>\n",
       "      <td>Politics</td>\n",
       "      <td>west bengal give acre land volvo</td>\n",
       "      <td>west bengal chief minister mamata banerjee thu...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14003</th>\n",
       "      <td>Politics</td>\n",
       "      <td>vijaya lakshmi st female un general assembly prez</td>\n",
       "      <td>indian diplomat politician vijaya lakshmi pand...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14004</th>\n",
       "      <td>Politics</td>\n",
       "      <td>tax board honour lakh honest taxpayer</td>\n",
       "      <td>central board direct tax honour lakh honest co...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Subject                                     Headline_lemma  \\\n",
       "14000  Politics                 uk ban fishing million sq km ocean   \n",
       "14001  Politics                 iimc get upgraded university naidu   \n",
       "14002  Politics                   west bengal give acre land volvo   \n",
       "14003  Politics  vijaya lakshmi st female un general assembly prez   \n",
       "14004  Politics              tax board honour lakh honest taxpayer   \n",
       "\n",
       "                                             Short_lemma  Subejct_encoded  \n",
       "14000  uk government thursday said ban commercial fis...              2.0  \n",
       "14001  process upgrade indian institute mass communic...              2.0  \n",
       "14002  west bengal chief minister mamata banerjee thu...              2.0  \n",
       "14003  indian diplomat politician vijaya lakshmi pand...              2.0  \n",
       "14004  central board direct tax honour lakh honest co...              2.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df2['Short_lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2=df2['Subejct_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train2, features_test2, labels_train2, labels_test2 = train_test_split(X2, y2, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train2 = vectorizer.fit_transform(features_train2)\n",
    "features_test2 = vectorizer.transform(features_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(features_train2.toarray(), labels_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train = model.score(features_train2.toarray(), labels_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_test = model.score(features_test2.toarray(), labels_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7760968229954615"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(features_test2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 23,   4,  11,   0,   3],\n",
       "       [  1,  98,  31,   2,  12],\n",
       "       [  1,   3, 297,   4,  11],\n",
       "       [  2,   5,  21,  25,   4],\n",
       "       [  0,   9,  22,   2,  70]], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(labels_test2,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n         0.0       0.85      0.56      0.68        41\\n         1.0       0.82      0.68      0.75       144\\n         2.0       0.78      0.94      0.85       316\\n         3.0       0.76      0.44      0.56        57\\n         4.0       0.70      0.68      0.69       103\\n\\n    accuracy                           0.78       661\\n   macro avg       0.78      0.66      0.70       661\\nweighted avg       0.78      0.78      0.77       661\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(labels_test2,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.78\n",
      "\n",
      "Micro Precision: 0.78\n",
      "Micro Recall: 0.78\n",
      "Micro F1-score: 0.78\n",
      "\n",
      "Macro Precision: 0.78\n",
      "Macro Recall: 0.66\n",
      "Macro F1-score: 0.70\n",
      "\n",
      "Weighted Precision: 0.78\n",
      "Weighted Recall: 0.78\n",
      "Weighted F1-score: 0.77\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       0.85      0.56      0.68        41\n",
      "     Class 2       0.82      0.68      0.75       144\n",
      "     Class 3       0.78      0.94      0.85       316\n",
      "     Class 4       0.76      0.44      0.56        57\n",
      "     Class 5       0.70      0.68      0.69       103\n",
      "\n",
      "    accuracy                           0.78       661\n",
      "   macro avg       0.78      0.66      0.70       661\n",
      "weighted avg       0.78      0.78      0.77       661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(labels_test2, y_pred)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(labels_test2, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(labels_test2, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(labels_test2, y_pred, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(labels_test2, y_pred, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(labels_test2, y_pred, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(labels_test2, y_pred, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(labels_test2, y_pred, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(labels_test2, y_pred, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(labels_test2, y_pred, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(labels_test2, y_pred, target_names=['Class 1', 'Class 2', 'Class 3','Class 4','Class 5']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_features='auto',random_state=1, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10], \"min_samples_split\" : [2, 4, 10,12,16], \"n_estimators\": [50, 100,400,700,1000]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "gs = gs.fit(features_train2.toarray(), labels_train2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=1)\n",
      "0.916418374615022\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_estimator_) \n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9046898638426626\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=1)\n",
    "rf.fit(features_train2.toarray(), labels_train2)\n",
    "y_predictions_rf = rf.predict(features_test2.toarray())\n",
    "acc = accuracy_score(labels_test2, y_predictions_rf)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 39,   0,   2,   0,   0],\n",
       "       [  0, 122,  18,   1,   3],\n",
       "       [  0,   1, 310,   2,   3],\n",
       "       [  0,   2,   9,  46,   0],\n",
       "       [  0,   2,  20,   0,  81]], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(labels_test2,y_predictions_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Micro Precision: 0.78\n",
      "Micro Recall: 0.90\n",
      "Micro F1-score: 0.90\n",
      "\n",
      "Macro Precision: 0.94\n",
      "Macro Recall: 0.87\n",
      "Macro F1-score: 0.90\n",
      "\n",
      "Weighted Precision: 0.91\n",
      "Weighted Recall: 0.90\n",
      "Weighted F1-score: 0.90\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       1.00      0.95      0.97        41\n",
      "     Class 2       0.96      0.85      0.90       144\n",
      "     Class 3       0.86      0.98      0.92       316\n",
      "     Class 4       0.94      0.81      0.87        57\n",
      "     Class 5       0.93      0.79      0.85       103\n",
      "\n",
      "    accuracy                           0.90       661\n",
      "   macro avg       0.94      0.87      0.90       661\n",
      "weighted avg       0.91      0.90      0.90       661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(labels_test2, y_predictions_rf)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(labels_test2, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(labels_test2, y_predictions_rf, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(labels_test2, y_predictions_rf, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(labels_test2, y_predictions_rf, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(labels_test2, y_predictions_rf, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(labels_test2, y_predictions_rf, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(labels_test2, y_predictions_rf, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(labels_test2, y_predictions_rf, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(labels_test2, y_predictions_rf, average='weighted')))\n",
    "\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(labels_test2, y_predictions_rf, target_names=['Class 1', 'Class 2', 'Class 3','Class 4','Class 5']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(p=2,weights='distance',n_neighbors=50)\n",
    "knn.fit(features_train2.toarray(), labels_train2)\n",
    "\n",
    "# Predict using model:\n",
    "\n",
    "y_predict_knn=knn.predict(features_test2.toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.85\n",
      "\n",
      "Micro Precision: 0.85\n",
      "Micro Recall: 0.85\n",
      "Micro F1-score: 0.85\n",
      "\n",
      "Macro Precision: 0.89\n",
      "Macro Recall: 0.76\n",
      "Macro F1-score: 0.81\n",
      "\n",
      "Weighted Precision: 0.86\n",
      "Weighted Recall: 0.85\n",
      "Weighted F1-score: 0.84\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       0.94      0.78      0.85        41\n",
      "     Class 2       0.90      0.78      0.84       144\n",
      "     Class 3       0.81      0.98      0.89       316\n",
      "     Class 4       0.93      0.49      0.64        57\n",
      "     Class 5       0.87      0.76      0.81       103\n",
      "\n",
      "    accuracy                           0.85       661\n",
      "   macro avg       0.89      0.76      0.81       661\n",
      "weighted avg       0.86      0.85      0.84       661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(labels_test2, y_predict_knn)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(labels_test2, y_predict_knn, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(labels_test2, y_predict_knn, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(labels_test2, y_predict_knn, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(labels_test2, y_predict_knn, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(labels_test2, y_predict_knn, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(labels_test2, y_predict_knn, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(labels_test2, y_predict_knn, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(labels_test2, y_predict_knn, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(labels_test2, y_predict_knn, average='weighted')))\n",
    "\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(labels_test2, y_predict_knn, target_names=['Class 1', 'Class 2', 'Class 3','Class 4','Class 5']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of Naive Bayes Model: 0.78\n",
      "\n",
      "\n",
      "Accuracy of KNN Model: 0.85\n",
      "\n",
      "\n",
      "Accuracy of Random Forest Model: 0.90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nAccuracy of Naive Bayes Model: {:.2f}\\n'.format(accuracy_score(labels_test2, y_pred)))\n",
    "print('\\nAccuracy of KNN Model: {:.2f}\\n'.format(accuracy_score(labels_test2, y_predict_knn)))\n",
    "print('\\nAccuracy of Random Forest Model: {:.2f}\\n'.format(accuracy_score(labels_test2, y_predictions_rf)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1-score of Naive Bayes Model: 0.77\n",
      "Weighted F1-score of KNN Model: 0.84\n",
      "Weighted F1-score of Random Forest: 0.90\n"
     ]
    }
   ],
   "source": [
    "print('Weighted F1-score of Naive Bayes Model: {:.2f}'.format(f1_score(labels_test2, y_pred, average='weighted')))\n",
    "print('Weighted F1-score of KNN Model: {:.2f}'.format(f1_score(labels_test2, y_predict_knn, average='weighted')))\n",
    "print('Weighted F1-score of Random Forest: {:.2f}'.format(f1_score(labels_test2, y_predictions_rf, average='weighted')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from our analysis that random forest model performs the best amongst the three chosen models. But one noticeable aspect here is the performance of a simple KNN model. With accuracy of 85% it is not much behind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
